{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEET_DATA = '../data/01_raw/product_sentiment.csv'\n",
    "LABEL_MAPPING = { \n",
    "    \"No emotion toward brand or product\": {\n",
    "        \"alt_label\": \"NEU\",\n",
    "        \"class\": 1,\n",
    "    },\n",
    "    \"Positive emotion\": {\n",
    "        \"alt_label\": \"POS\",\n",
    "        \"class\": 2,\n",
    "    },\n",
    "    \"Negative emotion\": {\n",
    "        \"alt_label\": \"NEG\",\n",
    "        \"class\": 0,\n",
    "    },\n",
    "}\n",
    "USE_CLEANED_TWEET = True\n",
    "\n",
    "MODEL_NAME = \"tfidf\"\n",
    "MODEL_FILENAME = f\"../data/07_model_output/{MODEL_NAME}.pkl\"\n",
    "\n",
    "# save filepath\n",
    "processed_indicator = 'raw'\n",
    "if USE_CLEANED_TWEET:\n",
    "    processed_indicator = 'cleaned'\n",
    "PREDICTION_FILEPATH = f\"../data/07_model_output/{MODEL_NAME}/{processed_indicator}_tweet_predicitons.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TWEET_DATA)\n",
    "df.rename(columns={'is_there_an_emotion_directed_at_a_brand_or_product': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "1. Remove \"I can't tell\" labels - 156 rows (1.7% of data) and any missing tweets (1 data point)\n",
    "2. Clean tweet text - remove links and `@` / `#` prefixes\n",
    "3. Rename the labels - see `LABEL_MAPPING`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def _strip_links(text):\n",
    "    link_regex = re.compile(\"((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)\", re.DOTALL)\n",
    "    links = re.findall(link_regex, text)\n",
    "    for link in links:\n",
    "        text = text.replace(link[0], \", \")\n",
    "    return text\n",
    "\n",
    "\n",
    "def _strip_all_entities(text):\n",
    "    entity_prefixes = [\"@\", \".@\", \"#\", \".#\"]\n",
    "    # replace all other punctuation with a space\n",
    "    # for separator in string.punctuation:\n",
    "    #     if separator not in entity_prefixes:\n",
    "    #         text = text.replace(separator, \" \")\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        word = word.strip()\n",
    "        if word:\n",
    "            if word[0] not in entity_prefixes:\n",
    "                words.append(word)\n",
    "    return \" \".join(words)\n",
    "\n",
    "def preprocess_tweet_text(text):\n",
    "    return _strip_all_entities(_strip_links(text))\n",
    "\n",
    "def rename_labels(row):\n",
    "    row['alt_label'] = LABEL_MAPPING[row['label']]['alt_label']\n",
    "    row['class'] = LABEL_MAPPING[row['label']]['class']\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len before cln: 9093, len after cln: 8936\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_text_cln</th>\n",
       "      <th>alt_label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Know about ? Awesome iPad/iPhone app that you'...</td>\n",
       "      <td>POS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Can not wait for 2 also. They should sale them...</td>\n",
       "      <td>POS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         tweet_text  \\\n",
       "0      0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1      1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2      2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at             label  \\\n",
       "0                          iPhone  Negative emotion   \n",
       "1              iPad or iPhone App  Positive emotion   \n",
       "2                            iPad  Positive emotion   \n",
       "\n",
       "                                      tweet_text_cln alt_label  class  \n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...       NEG      0  \n",
       "1  Know about ? Awesome iPad/iPhone app that you'...       POS      2  \n",
       "2  Can not wait for 2 also. They should sale them...       POS      2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove unknown labels and drop na\n",
    "df_cln = df.copy()[df['label'] != \"I can't tell\"].dropna(subset=['tweet_text'])\n",
    "len_before, len_after = len(df), len(df_cln)\n",
    "print(f'len before cln: {len_before}, len after cln: {len_after}')\n",
    "\n",
    "# clean text\n",
    "df_cln['tweet_text_cln'] = df_cln['tweet_text'].apply(preprocess_tweet_text)\n",
    "\n",
    "# rename labels\n",
    "df_cln = df_cln.apply(rename_labels, axis=1)\n",
    "df_cln.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train BoW model\n",
    "\n",
    "Bag of words model:\n",
    "1. Clean text, remove stopwords, lemmatize\n",
    "2. Split train/test\n",
    "3. fit TFIDF vectorizer\n",
    "4. Multiclass LogReg?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Clean text, remove stopwords, lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tommy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/tommy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tommy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/tommy/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before bow clean:\t Bisotã¢ location 06:10, 3/16 Austin, TX, USA {link} platform 2011 is killing... {link}\n",
      "after bow clean:\t bisot location austin tx usa link platform killing link\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_for_bow(text):\n",
    "    cln_text = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        # lower\n",
    "        word = word.lower()\n",
    "        # remove non-alpha\n",
    "        word = re.sub(\"[^A-Za-z]+\",\"\", word)\n",
    "        # stop word removal\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        # lemmatize\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        word = word.lstrip()\n",
    "        if word:\n",
    "            cln_text.append(word)\n",
    "    \n",
    "    return \" \".join(cln_text)\n",
    "\n",
    "df_cln['tweet_text_cln_bow'] = df_cln['tweet_text_cln'].apply(clean_for_bow)\n",
    "\n",
    "# show example\n",
    "_df_cln = df_cln.copy().sample(1)\n",
    "tweet_text_cln_ex = _df_cln['tweet_text_cln'].iloc[0]\n",
    "tweet_text_cln_bow_ex = _df_cln['tweet_text_cln_bow'].iloc[0]\n",
    "print(f'before bow clean:\\t {tweet_text_cln_ex}')\n",
    "print(f'after bow clean:\\t {tweet_text_cln_bow_ex}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (6702,), (6702,)\n",
      "Test: (2234,), (2234,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_cln['tweet_text_cln_bow'], df_cln['class'], test_size=0.25, random_state=40, stratify=df_cln['class'], shuffle=True)\n",
    "\n",
    "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. TFIDF vectorizer and 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;, LinearSVC(random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;, LinearSVC(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=0)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('clf', LinearSVC(random_state=0))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"tfidf\", TfidfVectorizer()),\n",
    "        (\"clf\", LinearSVC(random_state=0)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.6491228070175439,\n",
       "  'recall': 0.2605633802816901,\n",
       "  'f1-score': 0.37185929648241206,\n",
       "  'support': 142},\n",
       " '1': {'precision': 0.7263779527559056,\n",
       "  'recall': 0.821826280623608,\n",
       "  'f1-score': 0.7711598746081504,\n",
       "  'support': 1347},\n",
       " '2': {'precision': 0.6140888208269525,\n",
       "  'recall': 0.538255033557047,\n",
       "  'f1-score': 0.5736766809728183,\n",
       "  'support': 745},\n",
       " 'accuracy': 0.6915846016114593,\n",
       " 'macro avg': {'precision': 0.6631965268668006,\n",
       "  'recall': 0.5402148981541149,\n",
       "  'f1-score': 0.5722319506877936,\n",
       "  'support': 2234},\n",
       " 'weighted avg': {'precision': 0.6840209097917528,\n",
       "  'recall': 0.6915846016114593,\n",
       "  'f1-score': 0.6799218883269609,\n",
       "  'support': 2234}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_text_cln</th>\n",
       "      <th>alt_label</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet_text_cln_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>wesley g iphone hr tweeting dead need upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Know about ? Awesome iPad/iPhone app that you'...</td>\n",
       "      <td>POS</td>\n",
       "      <td>2</td>\n",
       "      <td>know awesome ipadiphone app likely appreciate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Can not wait for 2 also. They should sale them...</td>\n",
       "      <td>POS</td>\n",
       "      <td>2</td>\n",
       "      <td>wait also sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>I hope this year's festival isn't as crashy as...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>hope year festival nt crashy year iphone app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>great stuff on Fri Marissa Mayer (Google), Tim...</td>\n",
       "      <td>POS</td>\n",
       "      <td>2</td>\n",
       "      <td>great stuff fri marissa mayer google tim oreil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>9088</td>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Ipad everywhere. {link}</td>\n",
       "      <td>POS</td>\n",
       "      <td>2</td>\n",
       "      <td>ipad everywhere link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>9089</td>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Wave, buzz... RT We interrupt your regularly s...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>1</td>\n",
       "      <td>wave buzz rt interrupt regularly scheduled gee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>9090</td>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>1</td>\n",
       "      <td>google zeiger physician never reported potenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>9091</td>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>1</td>\n",
       "      <td>verizon iphone customer complained time fell b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>9092</td>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT G...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>1</td>\n",
       "      <td>rt google test checkin offer link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8936 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                         tweet_text  \\\n",
       "0         0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1         1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2         2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3         3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4         4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...     ...                                                ...   \n",
       "9088   9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089   9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090   9090  Google's Zeiger, a physician never reported po...   \n",
       "9091   9091  Some Verizon iPhone customers complained their...   \n",
       "9092   9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at                               label  \\\n",
       "0                             iPhone                    Negative emotion   \n",
       "1                 iPad or iPhone App                    Positive emotion   \n",
       "2                               iPad                    Positive emotion   \n",
       "3                 iPad or iPhone App                    Negative emotion   \n",
       "4                             Google                    Positive emotion   \n",
       "...                              ...                                 ...   \n",
       "9088                            iPad                    Positive emotion   \n",
       "9089                             NaN  No emotion toward brand or product   \n",
       "9090                             NaN  No emotion toward brand or product   \n",
       "9091                             NaN  No emotion toward brand or product   \n",
       "9092                             NaN  No emotion toward brand or product   \n",
       "\n",
       "                                         tweet_text_cln alt_label  class  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...       NEG      0   \n",
       "1     Know about ? Awesome iPad/iPhone app that you'...       POS      2   \n",
       "2     Can not wait for 2 also. They should sale them...       POS      2   \n",
       "3     I hope this year's festival isn't as crashy as...       NEG      0   \n",
       "4     great stuff on Fri Marissa Mayer (Google), Tim...       POS      2   \n",
       "...                                                 ...       ...    ...   \n",
       "9088                            Ipad everywhere. {link}       POS      2   \n",
       "9089  Wave, buzz... RT We interrupt your regularly s...       NEU      1   \n",
       "9090  Google's Zeiger, a physician never reported po...       NEU      1   \n",
       "9091  Some Verizon iPhone customers complained their...       NEU      1   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT G...       NEU      1   \n",
       "\n",
       "                                     tweet_text_cln_bow  \n",
       "0     wesley g iphone hr tweeting dead need upgrade ...  \n",
       "1     know awesome ipadiphone app likely appreciate ...  \n",
       "2                                        wait also sale  \n",
       "3          hope year festival nt crashy year iphone app  \n",
       "4     great stuff fri marissa mayer google tim oreil...  \n",
       "...                                                 ...  \n",
       "9088                               ipad everywhere link  \n",
       "9089  wave buzz rt interrupt regularly scheduled gee...  \n",
       "9090  google zeiger physician never reported potenti...  \n",
       "9091  verizon iphone customer complained time fell b...  \n",
       "9092                  rt google test checkin offer link  \n",
       "\n",
       "[8936 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6098    0\n",
       "7745    2\n",
       "5698    1\n",
       "798     1\n",
       "2009    1\n",
       "       ..\n",
       "7707    1\n",
       "7911    0\n",
       "2560    1\n",
       "6823    1\n",
       "6870    1\n",
       "Name: class, Length: 2234, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1524\n",
       "2     653\n",
       "0      57\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/07_model_output/tfidf.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline, MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = joblib.load(MODEL_FILENAME)\n",
    "pipeline.predict(['this is good'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['something'])\n",
    "CLASS_MAPPING = {\n",
    "    0:\"NEG\",\n",
    "    1:\"NEU\",\n",
    "    2:\"POS\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bef0c3fa9bf03e006bc12972ccf848bf44ed194c5ecfd9c8e7a0cda9a3be3e60"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('net-purpose-2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
